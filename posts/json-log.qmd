---
title: "Log model data in JSON format"
subtitle: > 
  This post shows you how you can gather information in your model as the 
  simulation progresses and generate JSON-formatted outputs that you can easily
  work with in R after the simulation is finished.
author: Kyle Baron
date: 02-11-2026
categories:
- evtools
---

```{r}
#| message: false
#| echo: false
library(mrgsolve)
library(here)
library(ggplot2)
library(dplyr)
theme_set(theme_bw() + theme(legend.position = "top"))
options(ggplot2.discrete.colour = RColorBrewer::brewer.pal(name = "Dark2", n = 8))
options(ggplot2.discrete.fill = RColorBrewer::brewer.pal(name = "Dark2", n = 8))
options(mrgsolve.project = here("posts/model/"))
```


# Introduction 

`mrgsolve` typically returns simulated outputs in rectangular format, with 
rows advancing in time for different subjects and columns giving you different 
outputs, including the simulated values, quantities calculated inside the 
model, items carried from the input data, etc. 

Sometimes, you'd like to record what is happening inside the simulation in a 
way that doesn't match up with the standard rectangular format. For example,

- **Did any one reach a critically low platelet count? **
  - Who was it?
  - When did it happen?
- **While running dynamic dosing simulations**
  - When were doses changed?
  - What were they changed from? and to?
  - What were the circumstances that lead to those dose adjustments?

This blog post will show you a simple way to log information as a simulation 
progresses and work with it after the simulation ends. We will use a C++
library to create records in JSON format for the data associated with these
different events. When the simulation ends, we'll recover that JSON code, parse 
it, and work with it in R. 

## Example

As an example, we'll run a one-compartment PK model with 100 mg administered at 
at different dosing intervals: every 6, 12, or 24 hours. 

Sounds pretty basic, right? The "new" part of this is we'll write some code 
_inside_ the model that will capture the predose concentration for each dose 
and write that information out to a file in JSON format. 

Don't get too hung up on the specifics here. I invented this _as an example_ 
to show you the mechanics of how to collect information inside your model and 
save it in a format you can get to later. You might have other, more nuanced 
use cases where you could use this same approach. 

## Example simulation

Here is the data set we'll use:

::: {.callout-note appearance="simple" collapse=true}
# See how we made the data

```{r}
e0 <- ev(amt = 100,   ii =  6, until = 145)
e1 <- ev(amt = 100,   ii = 12, until = 145)
e2 <- ev(amt = 100,   ii = 24, until = 145)
data <- as_data_set(e0, e1, e2) %>% mutate(interval = ii)
```

:::

```{r}
data
```

And we load the model here:

```{r}
#| message: false
mod <- mread("ctrough-log.mod")
```

An example simulation from the model is included below. 

```{r}
#| fig-height: 4
#| fig-width: 8
#| label: fig-conc-time-intro
#| fig-cap-location: top
#| fig-cap: Trough concentration versus time for different dosing intervals.
out <- mrgsim(mod, data, end = 240, delta = 0.1, recover = "interval")

sims <- as_tibble(out)

ggplot() + 
  geom_line(data = sims, aes(time/24, cp)) + 
  facet_wrap(~interval) + 
  scale_x_continuous(breaks = seq(0, 10, 2)) +
  scale_y_continuous(limits = c(0,20)) + 
  labs(x = "Time (days)", y = "Ctrough (ng/mL)")
```

As expected, the most accumulation is seen in the 6 hour dosing interval and 
the least in the 24 hour interval. In the model code, we'll show you out to 
log each pre-dose concentration for each individual and work with that after
the simulation ends. 


# The model 

We noted above that the PK model itself is pretty basic; the interesting parts 
include: 

1. Using the **BH** plugin to access a C++ library for generating JSON 
2. Collecting simulated data each time we administer a dose, and logging that 
   information in JSON format
3. Once the simulation is finished, write the JSON output to a file
4. We will read that file once the simulation is over and work with it
   
I've included the complete model code here; you can look at it to get a 
birds eye view. I'll be going block-by-block, explaining what is happening 
in the sections below. 

::: {.callout-note appearance="simple" collapse=true}
# View the full model code

```{r, code = readLines(here("posts/model/ctrough-log.mod"))}
#| filename: "posts/model/ctrough-log.mod"
#| eval: false

```

:::


## Blocks

```{r}
#| echo: false
code <- readLines(here("posts/model/ctrough-log.mod"))
blocks <- modelparse(code, drop_blank=FALSE, comment_re = "##")
b <- paste0("$", names(blocks))
blocks <- Map(\(x,y) {
  if(x[1]=="") {
    x <- x[-1]  
  }
  return(c(y,x))
}, blocks, b)  
```


Use the **BH** `$PLUGIN` to get access the the `boost::json` library.

```{cpp, code = blocks$PLUGIN, eval = FALSE}
```

Recall that a plugin is a way to bring additional syntax or code in to your 
model that you typically wouldn't use. Boost is an open-source C++ library, 
providing sophisticated, high-performance numerical computation code to your 
model. 

You can read about Boost here: <https://www.boost.org/>. 


In `$GLOBAL`, we include header the boost header files and invoke some 
additional C++ functionality for writing the json to file.

```{cpp, code = blocks$GLOBAL[1:7], eval = FALSE}
```

We also alias the `boost::json` namespace to a friendlier name (just `js`) and 
we initialize an array called `logg` where we will collect records for the 
json-formatted output. 

```{cpp, code = blocks$GLOBAL[9:11], eval = FALSE}
```

With this aliasing in place, we can initialize with array with `js::array logg`
rather than `boost::json::array logg`. 

There is full documentation for `boost::json` here: 
<https://www.boost.org/doc/libs/latest/libs/json/doc/html/index.html>.


In `$PREAMBLE`, we clear or reset json vector. 

```{cpp, code = blocks$PREAMBLE, eval = FALSE}
```

### Most of the work happens in `$ERROR`

```{cpp, code = blocks$ERROR, eval = FALSE}
```

# Run the simulation


## Simulate

```{r}
out <- mrgsim(mod, data, end = 240, delta = 0.1, recover = "interval")

out
```

## Read in the logged Ctrough data


The raw json code for the first two Ctrough points looks like this

```{r}
#| echo: false
code <- readLines(here("ctrough.json"))
x <- capture.output(print(jsonlite::prettify(code)))
```

```{json, code = x[1:15]}
#| filename: "ctrough.json"
#| eval: false
```


We'll use the `RcppSimdJson` package to read in the file we wrote in the model. 

::: {.column-margin}
RcppSimdJson: <https://cran.r-project.org/package=RcppSimdJson>
::::


```{r}
ct <- RcppSimdJson::fload(here("ctrough.json"))

slice(ct, 1:3, .by = id)
```



```{r}
#| fig-width: 8
#| fig-height: 4
#| label: fig-trough-time-results
#| fig-cap-location: top
#| fig-cap: Trough concentration versus time for different dosing intervals.
ggplot(ct, aes(time/24, ctrough, color = factor(interval))) + 
  geom_line() + geom_point() + 
  facet_grid(~interval) + 
  scale_y_continuous(limits = c(0, 16), breaks = seq(0,16,2)) + 
  scale_x_continuous(limits = c(0, 10), breaks = seq(0,10,2)) + 
  labs(x = "Time (days)", y = "Ctrough (ng/mL)")
```



```{r}
#| fig-height: 4
#| fig-width: 8
#| label: fig-trough-concentration-time-overlay-results
#| fig-cap-location: top
#| fig-cap: Concentration versus time; the shaded area is the Ctrough data.
sims <- as_tibble(out)

ggplot() + 
  geom_line(data = ct, aes(time/24, ctrough, col = factor(interval)), 
            lwd = 3, alpha = 0.6) + 
  geom_line(data = sims, aes(time/24, cp)) + 
  facet_wrap(~interval) + 
  scale_x_continuous(breaks = seq(0, 10, 2)) +
  scale_y_continuous(limits = c(0,20)) + 
  labs(x = "Time (days)", y = "Ctrough (ng/mL)")
```


# Alternate: write JSON output to model environment

```{r}
#| echo: false
code_env <- readLines(here("posts/model/ctrough-log-env.mod"))
blocks <- modelparse(code_env, drop_blank=FALSE, comment_re = "##")
b <- paste0("$", names(blocks))
blocks <- Map(\(x,y) {
  if(x[1]=="") {
    x <- x[-1]  
  }
  return(c(y,x))
}, blocks, b)  
```

It might not be that easy or safe to write outputs to a file on disk. In that
case, you can form the JSON object like we did in the model above, and 
assign it as an R object in the models environment. 

Part 2 of the `$ERROR` block from the original model has been updated to this

```{cpp, code = blocks$ERROR, eval = FALSE}

```


1. Serialize the JSON object
2. Get the environment from the model object
3. Assign the JSON result in the environment

::: {.callout-note appearance="simple" collapse=true}
# View the full alternate model code

```{r, code = code_env}
#| eval: false
#| filename: "posts/model/ctrough-log-env.mod"
```

:::

## Working example

```{r}
#| message: false
alt <- mread("ctrough-log-env.mod")

out <- mrgsim(alt, data, end = 240, delta = 0.1, recover = "interval")
```

```{r}
env <- env_get(out@mod)

ct2 <- RcppSimdJson::fparse(env$ctrough.json)

head(ct2)
```
